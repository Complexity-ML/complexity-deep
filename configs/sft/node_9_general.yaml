# Node 9: GENERAL Specialist
# Focus: Orchestration, routing, fallback

model:
  checkpoint: "./checkpoints-conv-sft/checkpoint_epoch11.pt"
  tokenizer: "./checkpoints-conv-sft"
  output: "./checkpoints-conv-sft-general"

training:
  epochs: 15
  batch_size: 8
  gradient_accumulation: 64
  learning_rate: 2e-5
  weight_decay: 0.01
  max_length: 4096
  warmup_ratio: 0.03
  gradient_checkpointing: true
  bf16: false

data:
  datasets:
    # Mix of all domains
    - name: "OpenAssistant/oasst1"
      weight: 0.20
      format: "oasst"
    - name: "teknium/OpenHermes-2.5"
      weight: 0.20
      format: "sharegpt"
    - name: "cognitivecomputations/dolphin"
      subset: "flan1m-alpaca-uncensored"
      weight: 0.16
      format: "alpaca"
    - name: "HuggingFaceH4/ultrachat_200k"
      split: "train_sft"
      weight: 0.14
      format: "ultrachat"
    - name: "Open-Orca/SlimOrca"
      weight: 0.16
      format: "sharegpt"
    - name: "WizardLM/WizardLM_evol_instruct_70k"
      weight: 0.14
      format: "alpaca"
  format: "sharegpt"
  max_samples: 500000

specialization:
  name: "general"
  skills:
    - general_assistant
    - routing
    - orchestration
    - fallback
    - conversation
    - instruction_following
    - multi_domain
